{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d13afc-c1d7-4b53-81ed-5c051c8a1ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "promedio: 0\n"
     ]
    }
   ],
   "source": [
    "# predecir el promedio de diametros de una micrografia de fibras, con transfer learning\n",
    "import numpy as np\n",
    "\n",
    "img = np.ones((256,256))\n",
    "\n",
    "\n",
    "\n",
    "def predict_fiber_mic_mean(img):\n",
    "    mean = 0\n",
    "    #to do\n",
    "    return mean\n",
    "\n",
    "promedio = predict_fiber_mic_mean(img)\n",
    "\n",
    "print(\"promedio:\", promedio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a7ecca-88e4-4ad6-97e9-040c74c86e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from utils.mmdataset import MicsMeansDataset\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e41d29e-e641-468e-9f90-1aff1d474538",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet50(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7736f6dc-63cb-493e-b2f8-fc4863ec37d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc9f7f47-29f4-4cb7-92b9-733e4d7e5d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tuning\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model_ft.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab4afe66-158b-4a79-b154-daf6f73e34be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 64, 112, 112]        9,408\n",
      "├─BatchNorm2d: 1-2                       [-1, 64, 112, 112]        128\n",
      "├─ReLU: 1-3                              [-1, 64, 112, 112]        --\n",
      "├─MaxPool2d: 1-4                         [-1, 64, 56, 56]          --\n",
      "├─Sequential: 1-5                        [-1, 256, 56, 56]         --\n",
      "|    └─Bottleneck: 2-1                   [-1, 256, 56, 56]         --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 64, 56, 56]          4,096\n",
      "|    |    └─BatchNorm2d: 3-2             [-1, 64, 56, 56]          128\n",
      "|    |    └─ReLU: 3-3                    [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-4                  [-1, 64, 56, 56]          36,864\n",
      "|    |    └─BatchNorm2d: 3-5             [-1, 64, 56, 56]          128\n",
      "|    |    └─ReLU: 3-6                    [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-7                  [-1, 256, 56, 56]         16,384\n",
      "|    |    └─BatchNorm2d: 3-8             [-1, 256, 56, 56]         512\n",
      "|    |    └─Sequential: 3-9              [-1, 256, 56, 56]         16,896\n",
      "|    |    └─ReLU: 3-10                   [-1, 256, 56, 56]         --\n",
      "|    └─Bottleneck: 2-2                   [-1, 256, 56, 56]         --\n",
      "|    |    └─Conv2d: 3-11                 [-1, 64, 56, 56]          16,384\n",
      "|    |    └─BatchNorm2d: 3-12            [-1, 64, 56, 56]          128\n",
      "|    |    └─ReLU: 3-13                   [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-14                 [-1, 64, 56, 56]          36,864\n",
      "|    |    └─BatchNorm2d: 3-15            [-1, 64, 56, 56]          128\n",
      "|    |    └─ReLU: 3-16                   [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-17                 [-1, 256, 56, 56]         16,384\n",
      "|    |    └─BatchNorm2d: 3-18            [-1, 256, 56, 56]         512\n",
      "|    |    └─ReLU: 3-19                   [-1, 256, 56, 56]         --\n",
      "|    └─Bottleneck: 2-3                   [-1, 256, 56, 56]         --\n",
      "|    |    └─Conv2d: 3-20                 [-1, 64, 56, 56]          16,384\n",
      "|    |    └─BatchNorm2d: 3-21            [-1, 64, 56, 56]          128\n",
      "|    |    └─ReLU: 3-22                   [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-23                 [-1, 64, 56, 56]          36,864\n",
      "|    |    └─BatchNorm2d: 3-24            [-1, 64, 56, 56]          128\n",
      "|    |    └─ReLU: 3-25                   [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-26                 [-1, 256, 56, 56]         16,384\n",
      "|    |    └─BatchNorm2d: 3-27            [-1, 256, 56, 56]         512\n",
      "|    |    └─ReLU: 3-28                   [-1, 256, 56, 56]         --\n",
      "├─Sequential: 1-6                        [-1, 512, 28, 28]         --\n",
      "|    └─Bottleneck: 2-4                   [-1, 512, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-29                 [-1, 128, 56, 56]         32,768\n",
      "|    |    └─BatchNorm2d: 3-30            [-1, 128, 56, 56]         256\n",
      "|    |    └─ReLU: 3-31                   [-1, 128, 56, 56]         --\n",
      "|    |    └─Conv2d: 3-32                 [-1, 128, 28, 28]         147,456\n",
      "|    |    └─BatchNorm2d: 3-33            [-1, 128, 28, 28]         256\n",
      "|    |    └─ReLU: 3-34                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-35                 [-1, 512, 28, 28]         65,536\n",
      "|    |    └─BatchNorm2d: 3-36            [-1, 512, 28, 28]         1,024\n",
      "|    |    └─Sequential: 3-37             [-1, 512, 28, 28]         132,096\n",
      "|    |    └─ReLU: 3-38                   [-1, 512, 28, 28]         --\n",
      "|    └─Bottleneck: 2-5                   [-1, 512, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-39                 [-1, 128, 28, 28]         65,536\n",
      "|    |    └─BatchNorm2d: 3-40            [-1, 128, 28, 28]         256\n",
      "|    |    └─ReLU: 3-41                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-42                 [-1, 128, 28, 28]         147,456\n",
      "|    |    └─BatchNorm2d: 3-43            [-1, 128, 28, 28]         256\n",
      "|    |    └─ReLU: 3-44                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-45                 [-1, 512, 28, 28]         65,536\n",
      "|    |    └─BatchNorm2d: 3-46            [-1, 512, 28, 28]         1,024\n",
      "|    |    └─ReLU: 3-47                   [-1, 512, 28, 28]         --\n",
      "|    └─Bottleneck: 2-6                   [-1, 512, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-48                 [-1, 128, 28, 28]         65,536\n",
      "|    |    └─BatchNorm2d: 3-49            [-1, 128, 28, 28]         256\n",
      "|    |    └─ReLU: 3-50                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-51                 [-1, 128, 28, 28]         147,456\n",
      "|    |    └─BatchNorm2d: 3-52            [-1, 128, 28, 28]         256\n",
      "|    |    └─ReLU: 3-53                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-54                 [-1, 512, 28, 28]         65,536\n",
      "|    |    └─BatchNorm2d: 3-55            [-1, 512, 28, 28]         1,024\n",
      "|    |    └─ReLU: 3-56                   [-1, 512, 28, 28]         --\n",
      "|    └─Bottleneck: 2-7                   [-1, 512, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-57                 [-1, 128, 28, 28]         65,536\n",
      "|    |    └─BatchNorm2d: 3-58            [-1, 128, 28, 28]         256\n",
      "|    |    └─ReLU: 3-59                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-60                 [-1, 128, 28, 28]         147,456\n",
      "|    |    └─BatchNorm2d: 3-61            [-1, 128, 28, 28]         256\n",
      "|    |    └─ReLU: 3-62                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-63                 [-1, 512, 28, 28]         65,536\n",
      "|    |    └─BatchNorm2d: 3-64            [-1, 512, 28, 28]         1,024\n",
      "|    |    └─ReLU: 3-65                   [-1, 512, 28, 28]         --\n",
      "├─Sequential: 1-7                        [-1, 1024, 14, 14]        --\n",
      "|    └─Bottleneck: 2-8                   [-1, 1024, 14, 14]        --\n",
      "|    |    └─Conv2d: 3-66                 [-1, 256, 28, 28]         131,072\n",
      "|    |    └─BatchNorm2d: 3-67            [-1, 256, 28, 28]         512\n",
      "|    |    └─ReLU: 3-68                   [-1, 256, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-69                 [-1, 256, 14, 14]         589,824\n",
      "|    |    └─BatchNorm2d: 3-70            [-1, 256, 14, 14]         512\n",
      "|    |    └─ReLU: 3-71                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-72                 [-1, 1024, 14, 14]        262,144\n",
      "|    |    └─BatchNorm2d: 3-73            [-1, 1024, 14, 14]        2,048\n",
      "|    |    └─Sequential: 3-74             [-1, 1024, 14, 14]        526,336\n",
      "|    |    └─ReLU: 3-75                   [-1, 1024, 14, 14]        --\n",
      "|    └─Bottleneck: 2-9                   [-1, 1024, 14, 14]        --\n",
      "|    |    └─Conv2d: 3-76                 [-1, 256, 14, 14]         262,144\n",
      "|    |    └─BatchNorm2d: 3-77            [-1, 256, 14, 14]         512\n",
      "|    |    └─ReLU: 3-78                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-79                 [-1, 256, 14, 14]         589,824\n",
      "|    |    └─BatchNorm2d: 3-80            [-1, 256, 14, 14]         512\n",
      "|    |    └─ReLU: 3-81                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-82                 [-1, 1024, 14, 14]        262,144\n",
      "|    |    └─BatchNorm2d: 3-83            [-1, 1024, 14, 14]        2,048\n",
      "|    |    └─ReLU: 3-84                   [-1, 1024, 14, 14]        --\n",
      "|    └─Bottleneck: 2-10                  [-1, 1024, 14, 14]        --\n",
      "|    |    └─Conv2d: 3-85                 [-1, 256, 14, 14]         262,144\n",
      "|    |    └─BatchNorm2d: 3-86            [-1, 256, 14, 14]         512\n",
      "|    |    └─ReLU: 3-87                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-88                 [-1, 256, 14, 14]         589,824\n",
      "|    |    └─BatchNorm2d: 3-89            [-1, 256, 14, 14]         512\n",
      "|    |    └─ReLU: 3-90                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-91                 [-1, 1024, 14, 14]        262,144\n",
      "|    |    └─BatchNorm2d: 3-92            [-1, 1024, 14, 14]        2,048\n",
      "|    |    └─ReLU: 3-93                   [-1, 1024, 14, 14]        --\n",
      "|    └─Bottleneck: 2-11                  [-1, 1024, 14, 14]        --\n",
      "|    |    └─Conv2d: 3-94                 [-1, 256, 14, 14]         262,144\n",
      "|    |    └─BatchNorm2d: 3-95            [-1, 256, 14, 14]         512\n",
      "|    |    └─ReLU: 3-96                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-97                 [-1, 256, 14, 14]         589,824\n",
      "|    |    └─BatchNorm2d: 3-98            [-1, 256, 14, 14]         512\n",
      "|    |    └─ReLU: 3-99                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-100                [-1, 1024, 14, 14]        262,144\n",
      "|    |    └─BatchNorm2d: 3-101           [-1, 1024, 14, 14]        2,048\n",
      "|    |    └─ReLU: 3-102                  [-1, 1024, 14, 14]        --\n",
      "|    └─Bottleneck: 2-12                  [-1, 1024, 14, 14]        --\n",
      "|    |    └─Conv2d: 3-103                [-1, 256, 14, 14]         262,144\n",
      "|    |    └─BatchNorm2d: 3-104           [-1, 256, 14, 14]         512\n",
      "|    |    └─ReLU: 3-105                  [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-106                [-1, 256, 14, 14]         589,824\n",
      "|    |    └─BatchNorm2d: 3-107           [-1, 256, 14, 14]         512\n",
      "|    |    └─ReLU: 3-108                  [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-109                [-1, 1024, 14, 14]        262,144\n",
      "|    |    └─BatchNorm2d: 3-110           [-1, 1024, 14, 14]        2,048\n",
      "|    |    └─ReLU: 3-111                  [-1, 1024, 14, 14]        --\n",
      "|    └─Bottleneck: 2-13                  [-1, 1024, 14, 14]        --\n",
      "|    |    └─Conv2d: 3-112                [-1, 256, 14, 14]         262,144\n",
      "|    |    └─BatchNorm2d: 3-113           [-1, 256, 14, 14]         512\n",
      "|    |    └─ReLU: 3-114                  [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-115                [-1, 256, 14, 14]         589,824\n",
      "|    |    └─BatchNorm2d: 3-116           [-1, 256, 14, 14]         512\n",
      "|    |    └─ReLU: 3-117                  [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-118                [-1, 1024, 14, 14]        262,144\n",
      "|    |    └─BatchNorm2d: 3-119           [-1, 1024, 14, 14]        2,048\n",
      "|    |    └─ReLU: 3-120                  [-1, 1024, 14, 14]        --\n",
      "├─Sequential: 1-8                        [-1, 2048, 7, 7]          --\n",
      "|    └─Bottleneck: 2-14                  [-1, 2048, 7, 7]          --\n",
      "|    |    └─Conv2d: 3-121                [-1, 512, 14, 14]         524,288\n",
      "|    |    └─BatchNorm2d: 3-122           [-1, 512, 14, 14]         1,024\n",
      "|    |    └─ReLU: 3-123                  [-1, 512, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-124                [-1, 512, 7, 7]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-125           [-1, 512, 7, 7]           1,024\n",
      "|    |    └─ReLU: 3-126                  [-1, 512, 7, 7]           --\n",
      "|    |    └─Conv2d: 3-127                [-1, 2048, 7, 7]          1,048,576\n",
      "|    |    └─BatchNorm2d: 3-128           [-1, 2048, 7, 7]          4,096\n",
      "|    |    └─Sequential: 3-129            [-1, 2048, 7, 7]          2,101,248\n",
      "|    |    └─ReLU: 3-130                  [-1, 2048, 7, 7]          --\n",
      "|    └─Bottleneck: 2-15                  [-1, 2048, 7, 7]          --\n",
      "|    |    └─Conv2d: 3-131                [-1, 512, 7, 7]           1,048,576\n",
      "|    |    └─BatchNorm2d: 3-132           [-1, 512, 7, 7]           1,024\n",
      "|    |    └─ReLU: 3-133                  [-1, 512, 7, 7]           --\n",
      "|    |    └─Conv2d: 3-134                [-1, 512, 7, 7]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-135           [-1, 512, 7, 7]           1,024\n",
      "|    |    └─ReLU: 3-136                  [-1, 512, 7, 7]           --\n",
      "|    |    └─Conv2d: 3-137                [-1, 2048, 7, 7]          1,048,576\n",
      "|    |    └─BatchNorm2d: 3-138           [-1, 2048, 7, 7]          4,096\n",
      "|    |    └─ReLU: 3-139                  [-1, 2048, 7, 7]          --\n",
      "|    └─Bottleneck: 2-16                  [-1, 2048, 7, 7]          --\n",
      "|    |    └─Conv2d: 3-140                [-1, 512, 7, 7]           1,048,576\n",
      "|    |    └─BatchNorm2d: 3-141           [-1, 512, 7, 7]           1,024\n",
      "|    |    └─ReLU: 3-142                  [-1, 512, 7, 7]           --\n",
      "|    |    └─Conv2d: 3-143                [-1, 512, 7, 7]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-144           [-1, 512, 7, 7]           1,024\n",
      "|    |    └─ReLU: 3-145                  [-1, 512, 7, 7]           --\n",
      "|    |    └─Conv2d: 3-146                [-1, 2048, 7, 7]          1,048,576\n",
      "|    |    └─BatchNorm2d: 3-147           [-1, 2048, 7, 7]          4,096\n",
      "|    |    └─ReLU: 3-148                  [-1, 2048, 7, 7]          --\n",
      "├─AvgPool2d: 1-9                         [-1, 2048, 1, 1]          --\n",
      "├─Linear: 1-10                           [-1, 1]                   2,049\n",
      "==========================================================================================\n",
      "Total params: 23,510,081\n",
      "Trainable params: 23,510,081\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 4.14\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 169.59\n",
      "Params size (MB): 89.68\n",
      "Estimated Total Size (MB): 259.84\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Conv2d: 1-1                            [-1, 64, 112, 112]        9,408\n",
       "├─BatchNorm2d: 1-2                       [-1, 64, 112, 112]        128\n",
       "├─ReLU: 1-3                              [-1, 64, 112, 112]        --\n",
       "├─MaxPool2d: 1-4                         [-1, 64, 56, 56]          --\n",
       "├─Sequential: 1-5                        [-1, 256, 56, 56]         --\n",
       "|    └─Bottleneck: 2-1                   [-1, 256, 56, 56]         --\n",
       "|    |    └─Conv2d: 3-1                  [-1, 64, 56, 56]          4,096\n",
       "|    |    └─BatchNorm2d: 3-2             [-1, 64, 56, 56]          128\n",
       "|    |    └─ReLU: 3-3                    [-1, 64, 56, 56]          --\n",
       "|    |    └─Conv2d: 3-4                  [-1, 64, 56, 56]          36,864\n",
       "|    |    └─BatchNorm2d: 3-5             [-1, 64, 56, 56]          128\n",
       "|    |    └─ReLU: 3-6                    [-1, 64, 56, 56]          --\n",
       "|    |    └─Conv2d: 3-7                  [-1, 256, 56, 56]         16,384\n",
       "|    |    └─BatchNorm2d: 3-8             [-1, 256, 56, 56]         512\n",
       "|    |    └─Sequential: 3-9              [-1, 256, 56, 56]         16,896\n",
       "|    |    └─ReLU: 3-10                   [-1, 256, 56, 56]         --\n",
       "|    └─Bottleneck: 2-2                   [-1, 256, 56, 56]         --\n",
       "|    |    └─Conv2d: 3-11                 [-1, 64, 56, 56]          16,384\n",
       "|    |    └─BatchNorm2d: 3-12            [-1, 64, 56, 56]          128\n",
       "|    |    └─ReLU: 3-13                   [-1, 64, 56, 56]          --\n",
       "|    |    └─Conv2d: 3-14                 [-1, 64, 56, 56]          36,864\n",
       "|    |    └─BatchNorm2d: 3-15            [-1, 64, 56, 56]          128\n",
       "|    |    └─ReLU: 3-16                   [-1, 64, 56, 56]          --\n",
       "|    |    └─Conv2d: 3-17                 [-1, 256, 56, 56]         16,384\n",
       "|    |    └─BatchNorm2d: 3-18            [-1, 256, 56, 56]         512\n",
       "|    |    └─ReLU: 3-19                   [-1, 256, 56, 56]         --\n",
       "|    └─Bottleneck: 2-3                   [-1, 256, 56, 56]         --\n",
       "|    |    └─Conv2d: 3-20                 [-1, 64, 56, 56]          16,384\n",
       "|    |    └─BatchNorm2d: 3-21            [-1, 64, 56, 56]          128\n",
       "|    |    └─ReLU: 3-22                   [-1, 64, 56, 56]          --\n",
       "|    |    └─Conv2d: 3-23                 [-1, 64, 56, 56]          36,864\n",
       "|    |    └─BatchNorm2d: 3-24            [-1, 64, 56, 56]          128\n",
       "|    |    └─ReLU: 3-25                   [-1, 64, 56, 56]          --\n",
       "|    |    └─Conv2d: 3-26                 [-1, 256, 56, 56]         16,384\n",
       "|    |    └─BatchNorm2d: 3-27            [-1, 256, 56, 56]         512\n",
       "|    |    └─ReLU: 3-28                   [-1, 256, 56, 56]         --\n",
       "├─Sequential: 1-6                        [-1, 512, 28, 28]         --\n",
       "|    └─Bottleneck: 2-4                   [-1, 512, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-29                 [-1, 128, 56, 56]         32,768\n",
       "|    |    └─BatchNorm2d: 3-30            [-1, 128, 56, 56]         256\n",
       "|    |    └─ReLU: 3-31                   [-1, 128, 56, 56]         --\n",
       "|    |    └─Conv2d: 3-32                 [-1, 128, 28, 28]         147,456\n",
       "|    |    └─BatchNorm2d: 3-33            [-1, 128, 28, 28]         256\n",
       "|    |    └─ReLU: 3-34                   [-1, 128, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-35                 [-1, 512, 28, 28]         65,536\n",
       "|    |    └─BatchNorm2d: 3-36            [-1, 512, 28, 28]         1,024\n",
       "|    |    └─Sequential: 3-37             [-1, 512, 28, 28]         132,096\n",
       "|    |    └─ReLU: 3-38                   [-1, 512, 28, 28]         --\n",
       "|    └─Bottleneck: 2-5                   [-1, 512, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-39                 [-1, 128, 28, 28]         65,536\n",
       "|    |    └─BatchNorm2d: 3-40            [-1, 128, 28, 28]         256\n",
       "|    |    └─ReLU: 3-41                   [-1, 128, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-42                 [-1, 128, 28, 28]         147,456\n",
       "|    |    └─BatchNorm2d: 3-43            [-1, 128, 28, 28]         256\n",
       "|    |    └─ReLU: 3-44                   [-1, 128, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-45                 [-1, 512, 28, 28]         65,536\n",
       "|    |    └─BatchNorm2d: 3-46            [-1, 512, 28, 28]         1,024\n",
       "|    |    └─ReLU: 3-47                   [-1, 512, 28, 28]         --\n",
       "|    └─Bottleneck: 2-6                   [-1, 512, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-48                 [-1, 128, 28, 28]         65,536\n",
       "|    |    └─BatchNorm2d: 3-49            [-1, 128, 28, 28]         256\n",
       "|    |    └─ReLU: 3-50                   [-1, 128, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-51                 [-1, 128, 28, 28]         147,456\n",
       "|    |    └─BatchNorm2d: 3-52            [-1, 128, 28, 28]         256\n",
       "|    |    └─ReLU: 3-53                   [-1, 128, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-54                 [-1, 512, 28, 28]         65,536\n",
       "|    |    └─BatchNorm2d: 3-55            [-1, 512, 28, 28]         1,024\n",
       "|    |    └─ReLU: 3-56                   [-1, 512, 28, 28]         --\n",
       "|    └─Bottleneck: 2-7                   [-1, 512, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-57                 [-1, 128, 28, 28]         65,536\n",
       "|    |    └─BatchNorm2d: 3-58            [-1, 128, 28, 28]         256\n",
       "|    |    └─ReLU: 3-59                   [-1, 128, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-60                 [-1, 128, 28, 28]         147,456\n",
       "|    |    └─BatchNorm2d: 3-61            [-1, 128, 28, 28]         256\n",
       "|    |    └─ReLU: 3-62                   [-1, 128, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-63                 [-1, 512, 28, 28]         65,536\n",
       "|    |    └─BatchNorm2d: 3-64            [-1, 512, 28, 28]         1,024\n",
       "|    |    └─ReLU: 3-65                   [-1, 512, 28, 28]         --\n",
       "├─Sequential: 1-7                        [-1, 1024, 14, 14]        --\n",
       "|    └─Bottleneck: 2-8                   [-1, 1024, 14, 14]        --\n",
       "|    |    └─Conv2d: 3-66                 [-1, 256, 28, 28]         131,072\n",
       "|    |    └─BatchNorm2d: 3-67            [-1, 256, 28, 28]         512\n",
       "|    |    └─ReLU: 3-68                   [-1, 256, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-69                 [-1, 256, 14, 14]         589,824\n",
       "|    |    └─BatchNorm2d: 3-70            [-1, 256, 14, 14]         512\n",
       "|    |    └─ReLU: 3-71                   [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-72                 [-1, 1024, 14, 14]        262,144\n",
       "|    |    └─BatchNorm2d: 3-73            [-1, 1024, 14, 14]        2,048\n",
       "|    |    └─Sequential: 3-74             [-1, 1024, 14, 14]        526,336\n",
       "|    |    └─ReLU: 3-75                   [-1, 1024, 14, 14]        --\n",
       "|    └─Bottleneck: 2-9                   [-1, 1024, 14, 14]        --\n",
       "|    |    └─Conv2d: 3-76                 [-1, 256, 14, 14]         262,144\n",
       "|    |    └─BatchNorm2d: 3-77            [-1, 256, 14, 14]         512\n",
       "|    |    └─ReLU: 3-78                   [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-79                 [-1, 256, 14, 14]         589,824\n",
       "|    |    └─BatchNorm2d: 3-80            [-1, 256, 14, 14]         512\n",
       "|    |    └─ReLU: 3-81                   [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-82                 [-1, 1024, 14, 14]        262,144\n",
       "|    |    └─BatchNorm2d: 3-83            [-1, 1024, 14, 14]        2,048\n",
       "|    |    └─ReLU: 3-84                   [-1, 1024, 14, 14]        --\n",
       "|    └─Bottleneck: 2-10                  [-1, 1024, 14, 14]        --\n",
       "|    |    └─Conv2d: 3-85                 [-1, 256, 14, 14]         262,144\n",
       "|    |    └─BatchNorm2d: 3-86            [-1, 256, 14, 14]         512\n",
       "|    |    └─ReLU: 3-87                   [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-88                 [-1, 256, 14, 14]         589,824\n",
       "|    |    └─BatchNorm2d: 3-89            [-1, 256, 14, 14]         512\n",
       "|    |    └─ReLU: 3-90                   [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-91                 [-1, 1024, 14, 14]        262,144\n",
       "|    |    └─BatchNorm2d: 3-92            [-1, 1024, 14, 14]        2,048\n",
       "|    |    └─ReLU: 3-93                   [-1, 1024, 14, 14]        --\n",
       "|    └─Bottleneck: 2-11                  [-1, 1024, 14, 14]        --\n",
       "|    |    └─Conv2d: 3-94                 [-1, 256, 14, 14]         262,144\n",
       "|    |    └─BatchNorm2d: 3-95            [-1, 256, 14, 14]         512\n",
       "|    |    └─ReLU: 3-96                   [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-97                 [-1, 256, 14, 14]         589,824\n",
       "|    |    └─BatchNorm2d: 3-98            [-1, 256, 14, 14]         512\n",
       "|    |    └─ReLU: 3-99                   [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-100                [-1, 1024, 14, 14]        262,144\n",
       "|    |    └─BatchNorm2d: 3-101           [-1, 1024, 14, 14]        2,048\n",
       "|    |    └─ReLU: 3-102                  [-1, 1024, 14, 14]        --\n",
       "|    └─Bottleneck: 2-12                  [-1, 1024, 14, 14]        --\n",
       "|    |    └─Conv2d: 3-103                [-1, 256, 14, 14]         262,144\n",
       "|    |    └─BatchNorm2d: 3-104           [-1, 256, 14, 14]         512\n",
       "|    |    └─ReLU: 3-105                  [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-106                [-1, 256, 14, 14]         589,824\n",
       "|    |    └─BatchNorm2d: 3-107           [-1, 256, 14, 14]         512\n",
       "|    |    └─ReLU: 3-108                  [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-109                [-1, 1024, 14, 14]        262,144\n",
       "|    |    └─BatchNorm2d: 3-110           [-1, 1024, 14, 14]        2,048\n",
       "|    |    └─ReLU: 3-111                  [-1, 1024, 14, 14]        --\n",
       "|    └─Bottleneck: 2-13                  [-1, 1024, 14, 14]        --\n",
       "|    |    └─Conv2d: 3-112                [-1, 256, 14, 14]         262,144\n",
       "|    |    └─BatchNorm2d: 3-113           [-1, 256, 14, 14]         512\n",
       "|    |    └─ReLU: 3-114                  [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-115                [-1, 256, 14, 14]         589,824\n",
       "|    |    └─BatchNorm2d: 3-116           [-1, 256, 14, 14]         512\n",
       "|    |    └─ReLU: 3-117                  [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-118                [-1, 1024, 14, 14]        262,144\n",
       "|    |    └─BatchNorm2d: 3-119           [-1, 1024, 14, 14]        2,048\n",
       "|    |    └─ReLU: 3-120                  [-1, 1024, 14, 14]        --\n",
       "├─Sequential: 1-8                        [-1, 2048, 7, 7]          --\n",
       "|    └─Bottleneck: 2-14                  [-1, 2048, 7, 7]          --\n",
       "|    |    └─Conv2d: 3-121                [-1, 512, 14, 14]         524,288\n",
       "|    |    └─BatchNorm2d: 3-122           [-1, 512, 14, 14]         1,024\n",
       "|    |    └─ReLU: 3-123                  [-1, 512, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-124                [-1, 512, 7, 7]           2,359,296\n",
       "|    |    └─BatchNorm2d: 3-125           [-1, 512, 7, 7]           1,024\n",
       "|    |    └─ReLU: 3-126                  [-1, 512, 7, 7]           --\n",
       "|    |    └─Conv2d: 3-127                [-1, 2048, 7, 7]          1,048,576\n",
       "|    |    └─BatchNorm2d: 3-128           [-1, 2048, 7, 7]          4,096\n",
       "|    |    └─Sequential: 3-129            [-1, 2048, 7, 7]          2,101,248\n",
       "|    |    └─ReLU: 3-130                  [-1, 2048, 7, 7]          --\n",
       "|    └─Bottleneck: 2-15                  [-1, 2048, 7, 7]          --\n",
       "|    |    └─Conv2d: 3-131                [-1, 512, 7, 7]           1,048,576\n",
       "|    |    └─BatchNorm2d: 3-132           [-1, 512, 7, 7]           1,024\n",
       "|    |    └─ReLU: 3-133                  [-1, 512, 7, 7]           --\n",
       "|    |    └─Conv2d: 3-134                [-1, 512, 7, 7]           2,359,296\n",
       "|    |    └─BatchNorm2d: 3-135           [-1, 512, 7, 7]           1,024\n",
       "|    |    └─ReLU: 3-136                  [-1, 512, 7, 7]           --\n",
       "|    |    └─Conv2d: 3-137                [-1, 2048, 7, 7]          1,048,576\n",
       "|    |    └─BatchNorm2d: 3-138           [-1, 2048, 7, 7]          4,096\n",
       "|    |    └─ReLU: 3-139                  [-1, 2048, 7, 7]          --\n",
       "|    └─Bottleneck: 2-16                  [-1, 2048, 7, 7]          --\n",
       "|    |    └─Conv2d: 3-140                [-1, 512, 7, 7]           1,048,576\n",
       "|    |    └─BatchNorm2d: 3-141           [-1, 512, 7, 7]           1,024\n",
       "|    |    └─ReLU: 3-142                  [-1, 512, 7, 7]           --\n",
       "|    |    └─Conv2d: 3-143                [-1, 512, 7, 7]           2,359,296\n",
       "|    |    └─BatchNorm2d: 3-144           [-1, 512, 7, 7]           1,024\n",
       "|    |    └─ReLU: 3-145                  [-1, 512, 7, 7]           --\n",
       "|    |    └─Conv2d: 3-146                [-1, 2048, 7, 7]          1,048,576\n",
       "|    |    └─BatchNorm2d: 3-147           [-1, 2048, 7, 7]          4,096\n",
       "|    |    └─ReLU: 3-148                  [-1, 2048, 7, 7]          --\n",
       "├─AvgPool2d: 1-9                         [-1, 2048, 1, 1]          --\n",
       "├─Linear: 1-10                           [-1, 1]                   2,049\n",
       "==========================================================================================\n",
       "Total params: 23,510,081\n",
       "Trainable params: 23,510,081\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 4.14\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 169.59\n",
       "Params size (MB): 89.68\n",
       "Estimated Total Size (MB): 259.84\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model_ft, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16363172-a344-4d8a-a160-dd6839f21719",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "val_percent = 0.2\n",
    "\n",
    "dir_mics = \"data_dm_overlapping/test/imgs/\"\n",
    "file_means = \"data_dm_overlapping/test/diameter_means.pkl\"\n",
    "img_scale = 1\n",
    "\n",
    "dataset = MicsMeansDataset(dir_mics, file_means, img_scale, transforms=transforms.Compose([\n",
    "                                                                    transforms.RandomResizedCrop(224),\n",
    "                                                                    transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.114, 0.114, 0.114],std=[0.237, 0.237, 0.237])\n",
    "                                                                ]))\n",
    "\n",
    "n_val = int(len(dataset) * val_percent)\n",
    "n_train = len(dataset) - n_val\n",
    "\n",
    "train_data, val_data = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0c65c21-116b-4755-9e00-f68132482742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 224, 224])\n",
      "tensor(7.6101, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f738d92f2e0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lote = next(iter(train_loader))\n",
    "\n",
    "print(lote['mics'].size())\n",
    "print(lote['means'][0])\n",
    "\n",
    "img = lote['mics'][0].permute(1,2,0)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614b9cd4-ae56-4404-98ab-3a19d791139b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0      3.1720      1.8253\n",
      "    1      1.8165      7.9634\n",
      "    2      1.7213      1.7435\n",
      "    3      1.6598      5.8505\n",
      "    4      1.7709      1.5312\n",
      "    5      1.5441     11.4201\n",
      "    6      1.6447      1.4209\n",
      "    7      1.5569      2.0221\n",
      "    8      1.5860      1.4883\n",
      "    9      1.7337      1.5105\n",
      "   10      1.6378      1.4856\n",
      "   11      1.6770      2.1617\n",
      "   12      1.5489      2.0106\n",
      "   13      1.5491      1.5529\n",
      "   14      1.6285      1.5247\n",
      "   15      1.6821      1.8693\n",
      "   16      1.5168      1.4582\n",
      "   17      1.5745      2.0002\n",
      "   18      1.5510      1.5053\n",
      "   19      1.5909      1.5064\n",
      "   20      1.6086      1.4335\n",
      "   21      1.6471      3.7708\n",
      "   22      1.5667      2.1009\n",
      "   23      1.5433      1.8048\n",
      "   24      1.5245      1.4438\n",
      "   25      1.5453      1.9273\n",
      "   26      1.6397      1.5550\n",
      "   27      1.4982      1.5354\n",
      "   28      1.6172      1.5253\n",
      "   29      1.5222      1.5015\n",
      "   30      1.6115      2.3751\n",
      "   31      1.4761      1.4812\n",
      "   32      1.5677      2.4218\n",
      "   33      1.5005      1.7011\n",
      "   34      1.5396      1.9727\n",
      "   35      1.5244      1.5346\n",
      "   36      1.5194      2.2969\n",
      "   37      1.4779      2.5753\n",
      "   38      1.4844      1.7874\n",
      "   39      1.4876      2.0889\n",
      "   40      1.4665      1.5644\n",
      "   41      1.4943      3.3442\n",
      "   42      1.5027      2.1912\n",
      "   43      1.5466      3.0383\n",
      "   44      1.4763      1.9833\n",
      "   45      1.5257      1.9601\n",
      "   46      1.5047      2.0250\n",
      "   47      1.4988      2.6428\n",
      "   48      1.5634     19.6109\n",
      "   49      1.5207      1.6180\n",
      "   50      1.5028      3.3135\n",
      "   51      1.5328      1.5764\n",
      "   52      1.4872      1.4372\n",
      "   53      1.4593      1.4205\n",
      "   54      1.5229      2.0064\n",
      "   55      1.5061      1.4589\n",
      "   56      1.4628      1.7430\n",
      "   57      1.5415      2.3302\n",
      "   58      1.4459      1.4003\n",
      "   59      1.4740      1.4934\n",
      "   60      1.5274      1.6979\n",
      "   61      1.4638      1.5583\n",
      "   62      1.4267      1.4653\n",
      "   63      1.4785      1.4162\n",
      "   64      1.4787      1.4274\n",
      "   65      1.4811      2.3207\n",
      "   66      1.4920      1.4391\n",
      "   67      1.4738      1.5030\n",
      "   68      1.4486      1.4841\n",
      "   69      1.4873      2.2266\n",
      "   70      1.4566      1.6076\n",
      "   71      1.4528      1.7240\n",
      "   72      1.4789      1.4263\n",
      "   73      1.4441      3.9761\n",
      "   74      1.5536      1.4499\n",
      "   75      1.5125      1.3964\n",
      "   76      1.5126      1.4039\n",
      "   77      1.4992      1.4732\n",
      "   78      1.4979      1.4252\n",
      "   79      1.4680      1.5183\n",
      "   80      1.4988      1.6432\n",
      "   81      1.5822      1.4027\n",
      "   82      1.4717      1.3932\n",
      "   83      1.5058      1.4148\n",
      "   84      1.4291      1.3973\n",
      "   85      1.4992      1.5731\n",
      "   86      1.4839      1.4122\n",
      "   87      1.4972      1.6149\n",
      "   88      1.4757      1.4089\n",
      "   89      1.4790      1.4095\n",
      "   90      1.4666      1.4034\n",
      "   91      1.5796      1.4120\n",
      "   92      1.5233      1.4377\n",
      "   93      1.4885      1.4131\n",
      "   94      1.4778      1.4850\n",
      "   95      1.4466      1.7508\n",
      "   96      1.5096      1.5118\n",
      "   97      1.4547      1.4156\n",
      "   98      1.4562      1.5048\n",
      "   99      1.4472      1.4071\n",
      "  100      1.4823      1.4440\n",
      "  101      1.4532      1.4042\n",
      "  102      1.4614      1.4410\n",
      "  103      1.4887      1.4087\n",
      "  104      1.4701      1.4702\n",
      "  105      1.4635      1.4009\n",
      "  106      1.4698      1.4145\n",
      "  107      1.4438      1.4543\n",
      "  108      1.4759      1.3999\n",
      "  109      1.4610      1.4080\n",
      "  110      1.4504      1.4463\n",
      "  111      1.4617      1.5043\n",
      "  112      1.4587      1.4554\n",
      "  113      1.4619      1.4333\n",
      "  114      1.4681      1.3972\n",
      "  115      1.4567      1.4109\n",
      "  116      1.4674      1.4073\n",
      "  117      1.4292      1.5210\n",
      "  118      1.4978      1.4043\n",
      "  119      1.4982      1.4043\n",
      "  120      1.4614      1.4137\n",
      "  121      1.4404      1.4054\n",
      "  122      1.4908      1.4069\n",
      "  123      1.4526      1.4207\n",
      "  124      1.4605      1.3991\n",
      "  125      1.4775      1.3998\n",
      "  126      1.4641      1.4451\n",
      "  127      1.4689      1.3912\n",
      "  128      1.4235      1.4005\n",
      "  129      1.4431      1.4581\n",
      "  130      1.4281      1.4217\n",
      "  131      1.4975      1.4279\n",
      "  132      1.4585      1.4055\n",
      "  133      1.4468      1.4120\n",
      "  153      1.4750      1.4048\n",
      "  154      1.5117      1.4123\n",
      "  155      1.4597      1.4111\n",
      "  156      1.4581      1.4686\n",
      "  157      1.4571      1.4086\n",
      "  158      1.4708      1.3996\n",
      "  159      1.4577      1.4374\n",
      "  160      1.4263      1.4130\n",
      "  161      1.4462      1.4088\n",
      "  162      1.4391      1.4369\n",
      "  163      1.4274      1.3994\n",
      "  164      1.4585      1.4146\n",
      "  165      1.4577      1.5932\n",
      "  166      1.4225      1.4392\n",
      "  167      1.4297      1.3983\n",
      "  168      1.4720      1.4025\n",
      "  169      1.4452      1.4134\n",
      "  170      1.4854      1.3998\n",
      "  171      1.4418      1.5954\n",
      "  172      1.4331      1.4261\n",
      "  173      1.4411      1.5315\n",
      "  174      1.4839      1.6515\n",
      "  175      1.4757      1.7847\n",
      "  176      1.4582      1.4251\n",
      "  177      1.4555      1.4643\n",
      "  178      1.4193      2.1111\n",
      "  179      1.4519      1.4008\n",
      "  180      1.4698      1.7514\n",
      "  181      1.4211      1.4005\n",
      "  182      1.4536      1.4790\n",
      "  183      1.4697      1.4661\n",
      "  184      1.4231      1.4110\n",
      "  185      1.4598      1.4045\n",
      "  186      1.4348      1.5628\n",
      "  187      1.4279      1.5931\n",
      "  188      1.4404      1.4073\n",
      "  189      1.4387      1.4597\n",
      "  190      1.4449      1.4039\n",
      "  191      1.4409      1.4100\n",
      "  192      1.4612      1.3935\n",
      "  193      1.4464      1.4181\n",
      "  194      1.4707      1.4038\n",
      "  195      1.4487      1.4450\n",
      "  196      1.4888      1.4035\n",
      "  197      1.4222      1.4798\n",
      "  198      1.4514      1.4082\n",
      "  199      1.4648      1.4473\n",
      "  200      1.4970      1.4068\n",
      "  201      1.4302      1.4126\n",
      "  202      1.4320      1.4391\n",
      "  203      1.4595      1.4934\n",
      "  204      1.4472      1.4521\n",
      "  205      1.4516      1.4264\n",
      "  206      1.4388      1.4549\n",
      "  207      1.4617      1.4355\n",
      "  208      1.4331      1.4044\n",
      "  209      1.4271      1.4622\n",
      "  210      1.4516      1.3980\n",
      "  211      1.4560      1.4021\n",
      "  212      1.4469      1.4059\n",
      "  213      1.4609      1.4787\n",
      "  214      1.4409      1.4299\n",
      "  215      1.4651      1.4374\n",
      "  216      1.4333      1.4479\n",
      "  217      1.4387      1.4586\n",
      "  218      1.4707      1.5452\n",
      "  219      1.4448      1.4346\n",
      "  220      1.4661      1.4180\n",
      "  221      1.4795      1.5954\n",
      "  222      1.4390      1.4621\n",
      "  223      1.4312      1.4162\n",
      "  224      1.4294      1.4010\n",
      "  225      1.4282      1.3998\n",
      "  226      1.4713      1.4206\n",
      "  227      1.4311      1.3983\n",
      "  228      1.4434      1.4292\n",
      "  229      1.4515      1.4137\n",
      "  230      1.4398      1.5411\n",
      "  231      1.4308      1.4055\n",
      "  232      1.4394      1.4036\n",
      "  233      1.4812      1.4027\n",
      "  234      1.4513      1.4084\n",
      "  235      1.4319      1.3999\n",
      "  236      1.4448      1.4075\n",
      "  237      1.4268      1.4226\n",
      "  238      1.4345      1.4331\n",
      "  239      1.4542      1.4661\n",
      "  240      1.4326      1.4022\n",
      "  241      1.4533      1.4090\n",
      "  242      1.4486      1.5701\n",
      "  243      1.4493      1.5205\n",
      "  244      1.4414      1.4608\n",
      "  245      1.4586      1.4078\n",
      "  246      1.4260      1.4522\n",
      "  247      1.4270      1.4875\n",
      "  248      1.4243      1.4542\n",
      "  249      1.4240      1.4069\n",
      "  250      1.4541      1.4346\n",
      "  251      1.4561      1.4154\n",
      "  252      1.4191      1.4034\n",
      "  253      1.4559      1.4038\n",
      "  254      1.4510      1.4050\n",
      "  255      1.4239      1.4016\n",
      "  256      1.4405      1.4008\n",
      "  257      1.4224      1.4033\n",
      "  258      1.4237      1.4320\n",
      "  259      1.4374      1.4427\n",
      "  260      1.4238      1.4292\n",
      "  261      1.4334      1.4094\n",
      "  262      1.4474      1.4647\n",
      "  263      1.4278      1.4001\n",
      "  264      1.4322      1.4276\n",
      "  265      1.4445      1.4187\n",
      "  266      1.4292      1.4577\n",
      "  267      1.4470      1.4123\n",
      "  268      1.4366      1.4104\n",
      "  269      1.4241      1.4010\n",
      "  270      1.4222      1.4430\n",
      "  271      1.4446      1.4346\n",
      "  272      1.4440      1.3957\n",
      "  273      1.4210      1.5025\n",
      "  274      1.4266      1.3960\n",
      "  275      1.4453      1.4875\n",
      "  276      1.4486      1.4025\n",
      "  277      1.4185      1.4363\n",
      "  278      1.4458      1.4166\n",
      "  279      1.4383      1.4081\n",
      "  280      1.4287      1.4149\n",
      "  281      1.4457      1.4966\n",
      "  282      1.4893      1.4004\n",
      "  283      1.4700      1.4024\n",
      "  284      1.4737      1.4098\n",
      "  285      1.4314      1.4360\n",
      "  286      1.4304      1.5047\n",
      "  287      1.4592      1.4032\n",
      "  288      1.4592      1.4014\n",
      "  289      1.4498      1.4237\n",
      "  290      1.4467      1.4181\n",
      "  291      1.4281      1.4203\n",
      "  292      1.4394      1.4586\n",
      "  293      1.4346      1.4065\n",
      "  294      1.4435      1.4187\n",
      "  295      1.4234      1.4409\n",
      "  296      1.4213      1.4219\n",
      "  297      1.4362      1.5291\n",
      "  298      1.4572      1.4255\n",
      "  299      1.4508      1.4198\n",
      "  300      1.4421      1.4201\n",
      "  301      1.4572      1.4116\n",
      "  302      1.4478      1.4008\n",
      "  303      1.4428      1.4039\n",
      "  304      1.4259      1.4480\n",
      "  305      1.4281      1.4016\n",
      "  306      1.4428      1.4114\n",
      "  307      1.4666      1.4563\n",
      "  308      1.4167      1.4002\n",
      "  309      1.4310      1.4022\n",
      "  310      1.4481      1.4023\n",
      "  311      1.4477      1.4368\n",
      "  312      1.4627      1.5974\n",
      "  313      1.4408      1.4050\n",
      "  314      1.4506      1.4495\n",
      "  315      1.4423      1.4029\n",
      "  316      1.4235      1.4518\n",
      "  317      1.4504      1.4186\n",
      "  318      1.4261      1.4373\n",
      "  319      1.4422      1.4349\n",
      "  320      1.4604      1.4005\n",
      "  321      1.4721      1.4039\n",
      "  322      1.4458      1.3996\n",
      "  323      1.4394      1.3983\n",
      "  324      1.4371      1.4501\n",
      "  325      1.4636      1.4764\n",
      "  326      1.4712      1.4098\n",
      "  327      1.4654      1.4467\n",
      "  328      1.4394      1.5069\n",
      "  329      1.4359      1.4098\n",
      "  330      1.4249      1.4715\n",
      "  331      1.4220      1.4414\n",
      "  332      1.4460      1.4273\n",
      "  333      1.4268      1.4057\n",
      "  334      1.4285      1.4380\n",
      "  335      1.4230      1.4005\n",
      "  336      1.4309      1.4297\n",
      "  337      1.4369      1.4903\n",
      "  338      1.4373      1.4026\n",
      "  339      1.4413      1.4077\n",
      "  340      1.4499      1.4276\n",
      "  341      1.4155      1.3997\n",
      "  342      1.4529      1.4159\n",
      "  343      1.4470      1.4186\n",
      "  344      1.4498      1.4269\n",
      "  345      1.4201      1.4133\n",
      "  346      1.4168      1.3999\n",
      "  347      1.4144      1.4509\n",
      "  348      1.4358      1.4105\n",
      "  349      1.4383      1.4139\n",
      "  350      1.4261      1.4027\n",
      "  351      1.4339      1.4912\n",
      "  352      1.4665      1.4089\n",
      "  353      1.4512      1.4298\n",
      "  354      1.4252      1.4008\n",
      "  355      1.4250      1.4029\n",
      "  356      1.4513      1.4680\n",
      "  357      1.4485      1.3980\n",
      "  358      1.4702      1.4640\n",
      "  359      1.4180      1.4043\n",
      "  360      1.4390      1.4490\n",
      "  361      1.4374      1.4030\n",
      "  362      1.4313      1.4630\n",
      "  363      1.4477      1.4016\n",
      "  364      1.4266      1.4156\n",
      "  365      1.4450      1.4059\n",
      "  366      1.4293      1.4920\n",
      "  367      1.4301      1.4149\n",
      "  368      1.4278      1.4121\n",
      "  369      1.4369      1.4396\n",
      "  370      1.4271      1.4001\n",
      "  371      1.4463      1.3951\n",
      "  372      1.4545      1.3974\n",
      "  373      1.4338      1.4136\n",
      "  374      1.4238      1.6810\n",
      "  375      1.4818      1.4018\n",
      "  376      1.4374      1.4443\n",
      "  377      1.4575      1.4016\n",
      "  378      1.4315      1.5387\n",
      "  379      1.4333      1.4119\n",
      "  380      1.4065      1.4276\n",
      "  381      1.4374      1.4171\n",
      "  382      1.4246      1.4107\n",
      "  383      1.4474      1.4354\n",
      "  384      1.4616      1.4005\n",
      "  385      1.4599      1.4108\n",
      "  386      1.4377      1.3989\n",
      "  387      1.4298      1.4023\n",
      "  388      1.4567      1.4283\n",
      "  389      1.4446      1.4226\n",
      "  390      1.4527      1.4070\n",
      "  391      1.4476      1.4178\n",
      "  392      1.4221      1.4144\n",
      "  393      1.4251      1.4260\n",
      "  394      1.4194      1.4243\n",
      "  395      1.4328      1.4075\n",
      "  396      1.4303      1.4016\n",
      "  397      1.4277      1.4190\n",
      "  398      1.4430      1.4010\n",
      "  399      1.4507      1.4050\n",
      "  400      1.4311      1.4020\n",
      "  401      1.4349      1.4027\n",
      "  402      1.4443      1.4277\n",
      "  403      1.4529      1.4056\n",
      "  404      1.4400      1.4192\n",
      "  405      1.4441      1.4352\n",
      "  406      1.4482      1.4072\n",
      "  407      1.4112      1.4229\n",
      "  408      1.4636      1.4323\n",
      "  409      1.4132      1.4083\n",
      "  410      1.4167      1.4019\n",
      "  411      1.4493      1.4060\n",
      "  412      1.4202      1.5237\n",
      "  413      1.4243      1.4531\n",
      "  414      1.4176      1.5479\n",
      "  415      1.4260      1.4590\n",
      "  416      1.4418      1.4268\n",
      "  417      1.4366      1.4388\n",
      "  418      1.4544      1.4262\n",
      "  419      1.4452      1.4015\n",
      "  420      1.4197      1.5613\n",
      "  421      1.4377      1.4011\n",
      "  422      1.4385      1.4687\n",
      "  423      1.4476      1.3995\n",
      "  424      1.4212      1.4004\n",
      "  425      1.4352      1.4429\n",
      "  426      1.4262      1.4051\n",
      "  427      1.4308      1.4511\n",
      "  428      1.4240      1.4173\n",
      "  429      1.4487      1.4584\n",
      "  430      1.4410      1.4408\n",
      "  431      1.4472      1.4133\n",
      "  432      1.4426      1.4079\n",
      "  433      1.4627      1.4069\n",
      "  434      1.4187      1.4191\n",
      "  435      1.4275      1.4999\n",
      "  436      1.4544      1.4024\n",
      "  437      1.4494      1.4026\n",
      "  438      1.4230      1.4012\n",
      "  439      1.4507      1.4050\n",
      "  440      1.4365      1.4197\n",
      "  441      1.4282      1.4063\n",
      "  442      1.4364      1.4672\n",
      "  443      1.4208      1.4535\n",
      "  444      1.4289      1.4012\n",
      "  445      1.4540      1.4758\n",
      "  446      1.4509      1.3992\n",
      "  447      1.4196      1.4172\n",
      "  448      1.4653      1.4032\n",
      "  449      1.4283      1.4031\n",
      "  450      1.4352      1.4107\n",
      "  451      1.4350      1.4316\n",
      "  452      1.4379      1.4071\n",
      "  453      1.4391      1.4131\n",
      "  454      1.4468      1.3967\n",
      "  455      1.4242      1.4008\n",
      "  456      1.4432      1.4240\n",
      "  457      1.4287      1.5479\n",
      "  458      1.4449      1.4082\n",
      "  459      1.4347      1.4181\n",
      "  460      1.4362      1.4738\n",
      "  461      1.4379      1.4088\n",
      "  462      1.4472      1.4074\n",
      "  463      1.4544      1.4097\n",
      "  464      1.4346      1.4338\n",
      "  465      1.4391      1.4179\n",
      "  466      1.4202      1.4011\n",
      "  467      1.4221      1.4139\n",
      "  468      1.4229      1.4065\n",
      "  469      1.4254      1.4212\n",
      "  470      1.4462      1.4194\n",
      "  471      1.4483      1.4007\n",
      "  472      1.4573      1.4887\n",
      "  473      1.4299      1.4439\n",
      "  474      1.4263      1.4220\n",
      "  475      1.4226      1.4270\n",
      "  476      1.4197      1.4019\n",
      "  477      1.4295      1.4080\n",
      "  478      1.4544      1.4159\n",
      "  479      1.4214      1.4287\n",
      "  480      1.4280      1.4592\n",
      "  481      1.4325      1.4116\n",
      "  482      1.4353      1.3987\n",
      "  483      1.4283      1.4079\n",
      "  484      1.4183      1.4272\n",
      "  485      1.4625      1.4952\n",
      "  486      1.4153      1.4004\n",
      "  487      1.4044      1.4133\n",
      "  488      1.4257      1.4048\n",
      "  489      1.4146      1.4993\n",
      "  490      1.4130      1.4041\n",
      "  491      1.4510      1.4321\n",
      "  492      1.4233      1.4688\n",
      "  493      1.4308      1.4480\n",
      "  494      1.4382      1.4013\n",
      "  495      1.4490      1.4246\n",
      "  496      1.4314      1.4741\n",
      "  497      1.4186      1.4103\n",
      "  498      1.4122      1.3994\n",
      "  499      1.4222      1.4669\n",
      "  500      1.4352      1.3998\n",
      "  501      1.4233      1.6089\n",
      "  502      1.4358      1.3999\n",
      "  503      1.4125      1.4046\n",
      "  504      1.4445      1.4202\n",
      "  505      1.4271      1.4044\n",
      "  506      1.4198      1.3991\n",
      "  507      1.4180      1.4015\n",
      "  508      1.4289      1.4108\n",
      "  509      1.4385      1.4160\n",
      "  510      1.4360      1.4039\n",
      "  511      1.4092      1.4736\n",
      "  512      1.4237      1.4006\n",
      "  513      1.4330      1.4139\n",
      "  514      1.4480      1.4029\n",
      "  515      1.4377      1.4178\n",
      "  516      1.4257      1.4223\n",
      "  517      1.4285      1.4012\n",
      "  518      1.4209      1.4183\n",
      "  519      1.4392      1.4410\n",
      "  520      1.4298      1.4069\n",
      "  521      1.4252      1.4130\n",
      "  522      1.4320      1.4080\n",
      "  523      1.4177      1.4001\n",
      "  524      1.4255      1.4043\n",
      "  525      1.4134      1.4102\n",
      "  526      1.4255      1.4222\n",
      "  527      1.4215      1.4034\n",
      "  528      1.4268      1.4055\n",
      "  529      1.4172      1.4422\n",
      "  530      1.4439      1.4271\n",
      "  531      1.4366      1.4261\n",
      "  532      1.4096      1.4584\n",
      "  533      1.4475      1.4192\n",
      "  534      1.4181      1.4003\n",
      "  535      1.4219      1.4008\n",
      "  536      1.4278      1.4036\n",
      "  537      1.4089      1.4281\n",
      "  538      1.4443      1.4083\n",
      "  539      1.4323      1.4029\n",
      "  540      1.4407      1.4063\n",
      "  541      1.4328      1.4834\n",
      "  542      1.4165      1.4093\n",
      "  543      1.4142      1.4054\n",
      "  544      1.4322      1.4062\n",
      "  545      1.4260      1.4047\n",
      "  546      1.4422      1.4125\n",
      "  547      1.4318      1.3991\n",
      "  548      1.4204      1.4030\n",
      "  549      1.4157      1.5140\n",
      "  550      1.4542      1.4007\n",
      "  551      1.4283      1.4191\n",
      "  552      1.4361      1.4156\n",
      "  553      1.4297      1.4015\n",
      "  554      1.4400      1.4080\n",
      "  555      1.4134      1.4538\n",
      "  556      1.4192      1.4031\n",
      "  557      1.4242      1.4061\n",
      "  558      1.4281      1.4400\n",
      "  559      1.4255      1.4395\n",
      "  560      1.4213      1.4124\n",
      "  561      1.4284      1.3993\n",
      "  562      1.4383      1.4316\n",
      "  563      1.4319      1.4088\n",
      "  564      1.4408      1.4073\n",
      "  565      1.4244      1.4305\n",
      "  566      1.4199      1.4477\n",
      "  567      1.4483      1.3942\n",
      "  568      1.3944      1.3997\n",
      "  569      1.4082      1.4071\n",
      "  570      1.4329      1.4015\n",
      "  571      1.4310      1.4246\n",
      "  572      1.4232      1.4144\n",
      "  573      1.4197      1.4461\n",
      "  574      1.4189      1.3965\n",
      "  575      1.4019      1.4251\n",
      "  576      1.4222      1.3961\n",
      "  577      1.4267      1.4045\n",
      "  578      1.4145      1.4915\n",
      "  579      1.4526      1.3965\n",
      "  580      1.4102      1.4007\n",
      "  581      1.4170      1.3965\n",
      "  582      1.4230      1.4028\n",
      "  583      1.4165      1.4039\n",
      "  584      1.4085      1.4015\n",
      "  585      1.4140      1.5110\n",
      "  586      1.4156      1.4575\n",
      "  587      1.4462      1.4163\n",
      "  588      1.4310      1.4064\n",
      "  589      1.4216      1.3996\n",
      "  590      1.4310      1.4096\n",
      "  591      1.4197      1.4130\n",
      "  592      1.4181      1.4296\n",
      "  593      1.4304      1.4187\n",
      "  594      1.4231      1.4015\n"
     ]
    }
   ],
   "source": [
    "# trainning:\n",
    "\n",
    "num_epochs = 1000\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model_ft.train()\n",
    "    train_epoch_loss = 0\n",
    "    \n",
    "    for lote in train_loader:\n",
    "        mics,means = lote['mics'],lote['means']\n",
    "        mics = mics.to(device, dtype=torch.float32)\n",
    "        means = means.to(device, dtype=torch.float32)\n",
    "    \n",
    "        pred_means = model_ft(mics)\n",
    "        loss = criterion(pred_means, means)\n",
    "        train_epoch_loss += loss.item() * mics.size(0)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    train_losses.append(train_epoch_loss/len(train_data))\n",
    "    \n",
    "    model_ft.eval()\n",
    "    val_epoch_loss = 0\n",
    "    \n",
    "    for lote in val_loader:\n",
    "        mics,means = lote['mics'],lote['means']\n",
    "        mics = mics.to(device, dtype=torch.float32)\n",
    "        means = means.to(device, dtype=torch.float32)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            pred_means = model_ft(mics)\n",
    "            loss = criterion(pred_means, means)\n",
    "        \n",
    "        val_epoch_loss += loss.item() * mics.size(0)\n",
    "        \n",
    "    val_losses.append(val_epoch_loss/len(val_data))\n",
    "    \n",
    "    print(\"%5d %11.4f %11.4f\" % (epoch, train_epoch_loss/len(train_data), val_epoch_loss/len(val_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2272a2-0409-4f45-a3b8-3bbaa8dd9468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iaenv",
   "language": "python",
   "name": "iaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
